# src/easy_apply/form_processors/textbox_processor.py
"""
Processor for text input (<input type="text">, <input type="number">) and
textarea fields within LinkedIn Easy Apply forms.
"""
from __future__ import annotations 
from typing import Tuple, Final, Optional, Any, TYPE_CHECKING

from loguru import logger
from selenium.common import (
    NoSuchElementException, StaleElementReferenceException,
    InvalidElementStateException, ElementNotInteractableException, TimeoutException
)
from selenium.webdriver.common.by import By
from selenium.webdriver.remote.webelement import WebElement
from selenium.webdriver.support import expected_conditions as EC

# Assuming BaseProcessor correctly imports dependencies
from .base_processor import BaseProcessor
# Assuming Job object definition is available
if TYPE_CHECKING:
    from src.job import Job 
else:
    Job: Any = object          

# Assuming LLMError is defined in the llm package
try:
    from src.llm import LLMError
except ImportError:
     logger.warning("LLMError not found, using base Exception for LLM issues.")
     LLMError = Exception # type: ignore


class TextboxProcessor(BaseProcessor):
    """
    Handles filling text-based input fields (single-line, multi-line, numeric).

    Determines the question type, retrieves answers from cache or generates
    them using the LLM, and enters the text into the field. Handles specific
    questions that always require fresh generation.
    """

    # Questions that should ALWAYS be freshly generated by the LLM (case-insensitive check)
    # These often require context specific to the current job.
    QUESTIONS_REQUIRING_FRESH_ANSWERS: Final[Tuple[str, ...]] = (
        "headline",
        "cover letter",
        "why are you interested", # Partial match
        "why do you want to work here",
        "why are you a good fit", # Partial match
        "tell us about yourself",
        "what makes you unique",
        "what are your strengths",
        "what are your weaknesses",
        "salary expectation", # Usually requires context
        "notice period", # Can change
    )

    # Fallback values if LLM fails
    FALLBACK_TEXT_ANSWER: Final[str] = "As per my resume."
    FALLBACK_NUMERIC_ANSWER: Final[str] = "0" # Use string "0" for consistency with send_keys

    def handle(self, section: WebElement, job: Job) -> bool:
        """
        Detects and fills a textbox or textarea field within the given section.

        Prioritizes known structures for newer LinkedIn UI before falling back
        to older/generic structures.

        Args:
            section (WebElement): The WebElement representing the form section.
            job (Job): The job object for context.

        Returns:
            bool: True if a text field was found and handled, False otherwise.
        """
        logger.debug("TextboxProcessor: Scanning section for text input/textarea fields.")

        handled = False
        # --- Strategy 1: New 'artdeco' structure ---
        try:
            selectors = self.selectors.get("new", {})
            textarea_cls = selectors.get("textarea")
            input_cls = selectors.get("input")
            field: Optional[WebElement] = None
            is_textarea = False

            # Prioritize textarea if both input classes are present
            if textarea_cls:
                textareas = section.find_elements(By.CLASS_NAME, textarea_cls)
                if textareas and textareas[0].is_displayed():
                    field = textareas[0]
                    is_textarea = True
                    logger.debug("Found visible <textarea> in 'new' structure.")

            # If no textarea, look for standard input
            if not field and input_cls:
                inputs = section.find_elements(By.CLASS_NAME, input_cls)
                 # Filter out hidden, file, checkbox, radio inputs that might share base class
                visible_text_inputs = [
                    inp for inp in inputs
                    if inp.is_displayed() and inp.get_attribute("type") not in ['file', 'checkbox', 'radio', 'hidden']
                ]
                if visible_text_inputs:
                    field = visible_text_inputs[0]
                    logger.debug("Found visible text <input> in 'new' structure.")

            if field:
                handled = self._process_text_field(field, section, job, is_textarea)

        except StaleElementReferenceException:
            logger.warning("Stale element reference while searching for 'new structure' text fields.")
            # Continue to fallback
        except Exception as e:
            logger.debug(f"Did not find or failed processing 'new structure' text field: {e}", exc_info=False)
            # Continue to fallback

        if handled:
            return True

        # --- Strategy 2: Old/Generic structure ---
        if not handled:
            logger.debug("Searching for 'old/generic' text fields...")
            try:
                # Find any visible input (excluding specific types) or textarea
                text_inputs = [
                    el for el in section.find_elements(By.TAG_NAME, "input")
                    if el.is_displayed() and el.get_attribute("type") not in ['file', 'checkbox', 'radio', 'hidden', 'submit', 'button', 'image']
                ]
                text_areas = [
                    el for el in section.find_elements(By.TAG_NAME, "textarea")
                    if el.is_displayed()
                ]

                all_fields = text_areas + text_inputs # Prioritize textareas if both exist

                if not all_fields:
                    logger.trace("No old/generic text fields found.")
                    return False

                field = all_fields[0] # Process the first one found
                is_textarea = field.tag_name == 'textarea'
                logger.debug(f"Found old/generic text field (tag: {field.tag_name}).")

                handled = self._process_text_field(field, section, job, is_textarea)

            except StaleElementReferenceException:
                logger.warning("Stale element reference while searching for 'old/generic' text fields.")
                return False
            except Exception as e:
                logger.error(f"Error searching/handling 'old/generic' text field: {e}", exc_info=True)
                return False

        if not handled:
            logger.trace("TextboxProcessor: No suitable text field found in section.")

        return handled


    def _process_text_field(self, field: WebElement, section: WebElement, job: Job, is_textarea: bool) -> bool:
        """Helper to process a found text field (input or textarea)."""
        try:
             # Wait briefly for the field to be fully ready
            self.wait.until(EC.visibility_of(field))
            self.wait.until(lambda d: field.is_enabled())

            question_text, qtype = self._extract_question_info(field, section, is_textarea)
            logger.debug(f"Processing field for question: '{question_text}' (Type: {qtype})")

            answer = self._get_answer_for_field(question_text, qtype, job, is_textarea)

            if answer is None: # Handle case where getting answer fails
                 logger.error(f"Could not determine an answer for '{question_text}'. Skipping field.")
                 return False

            self.enter_text(field, answer) # BaseProcessor handles entering text
            logger.info(f"Filled field '{question_text}' successfully.")
            return True

        except StaleElementReferenceException:
             logger.warning("Stale element reference encountered while processing text field.")
             return False
        except (TimeoutException, ElementNotInteractableException) as e:
             logger.error(f"Field for '{question_text}' not ready for interaction: {e.__class__.__name__}")
             return False
        except Exception as e:
            logger.error(f"Unexpected error processing text field for '{question_text}': {e}", exc_info=True)
            return False


    def _extract_question_info(
        self,
        field: WebElement,
        section: WebElement,
        is_textarea: bool
    ) -> Tuple[str, str]:
        """
        1. <input type="number">                   ➜ numeric
        2. id termina em '-numeric' ou contém 'numeric' ➜ numeric
        3. Caso contrário                          ➜ textbox
        """
        # ── as variáveis originais ───────────────────────────
        question = "Unknown Question"
        qtype = "textbox"

        try:
            # agora pode levantar RuntimeError
            question = self.extract_question_text(section)

            # heurística 1 – atributo type
            field_type_attr = (field.get_attribute("type") or "").lower()
            is_numeric_type = field_type_attr == "number"

            # heurística 2 – id
            id_attr = (field.get_attribute("id") or "").lower()
            is_numeric_id = id_attr.endswith("-numeric") or "numeric" in id_attr

            numeric_hint = is_numeric_type or is_numeric_id

            # decisão final
            if numeric_hint and not is_textarea:
                qtype = "numeric"
            else:
                qtype = "textbox"

        except RuntimeError:
            # Propaga o erro “não foi possível extrair a pergunta”
            raise
        except Exception as e:
            # Outros erros inesperados ainda podem ser registrados
            logger.warning(
                f"Failed to determine question info accurately: {e}", exc_info=False
            )
            if question == "Unknown Question":
                question = "Unknown Text Field"

        logger.trace(f"Determined question='{question}', type='{qtype}'")
        return question, qtype


    def _get_answer_for_field(self, question: str, qtype: str, job: Job, is_textarea: bool) -> Optional[str]:
        """
        Retrieves or generates an appropriate answer for the text field.

        Checks if the question requires a fresh answer, then checks cache,
        otherwise generates using the LLM.

        Args:
            question (str): The sanitized question text.
            qtype (str): 'textbox' or 'numeric'.
            job (Job): The current job object.
            is_textarea (bool): True if the field is a textarea.

        Returns:
            Optional[str]: The answer string, or None if generation fails.
        """
        question_lower = question.lower() # For case-insensitive checks

        # Check if question requires fresh generation
        if any(blk in question_lower for blk in self.QUESTIONS_REQUIRING_FRESH_ANSWERS):
            logger.info(f"Question '{question}' requires fresh generation.")
            # Determine character limit for text generation
            # Longer limit for textareas, especially cover letter related ones
            char_limit = 2000 if is_textarea and "cover letter" in question_lower else (500 if is_textarea else None)
            return self._generate_llm_answer(question, job, numeric=(qtype == "numeric"), char_limit=char_limit)

        # Try cache first
        cached_answer = self.get_existing_answer(question, qtype)
        if cached_answer is not None: # Explicitly check for None
            logger.debug(f"Using cached answer for '{question}'.")
            return cached_answer

        # Generate new answer if not in cache and not blacklisted
        logger.info(f"No cached answer for '{question}'. Generating new answer.")
        answer = self._generate_llm_answer(question, job, numeric=(qtype == "numeric"))

        if answer is not None:
             # Save the newly generated answer (only if not None)
             self.save_answer(question, qtype, answer)
        # Return the generated answer (which might be None if LLM failed)
        return answer


    def _generate_llm_answer(
        self,
        question: str,
        job: Job,
        *,
        numeric: bool = False,
        char_limit: Optional[int] = None,
    ) -> Optional[str]:
        """
        Calls the appropriate LLM method to generate an answer.

        Handles setting the job context and selecting the correct LLM function
        based on whether a numeric or text answer is required.

        Args:
            question (str): The question text.
            job (Job): The current job object.
            numeric (bool): True if a numeric answer is expected.
            char_limit (Optional[int]): Max character limit for simple text answers.

        Returns:
            Optional[str]: The generated answer string, or None if the LLM call fails.
        """
        fallback_answer = self.FALLBACK_NUMERIC_ANSWER if numeric else self.FALLBACK_TEXT_ANSWER
        logger.debug(f"Requesting LLM answer for '{question}' (Numeric={numeric}, Limit={char_limit})")

        try:
            # Ensure LLM processor is available and has needed methods
            if not hasattr(self.llm_processor, 'set_current_job'):
                 logger.error("LLMProcessor missing 'set_current_job' method.")
                 return fallback_answer # Use fallback if LLM invalid

            # Set job context - This is crucial for relevant answers
            # This assumes set_current_job is efficient and doesn't have side effects
            # if called multiple times for the same job within a form step.
            # If it's expensive, consider setting it once per form step.
            self.llm_processor.set_current_job(job)

            answer: Optional[Any] = None # Initialize answer variable
            if numeric:
                if not hasattr(self.llm_processor, 'answer_question_numeric'):
                     logger.error("LLMProcessor missing 'answer_question_numeric' method.")
                     return fallback_answer
                answer = self.llm_processor.answer_question_numeric(question)
            else:
                 if not hasattr(self.llm_processor, 'answer_question_simple'):
                     logger.error("LLMProcessor missing 'answer_question_simple' method.")
                     return fallback_answer
                 # Use provided limit or default from LLM processor
                 limit = char_limit # or self.llm_processor.DEFAULT_ANSWER_CHAR_LIMIT (Assume LLM handles default if None)
                 answer = self.llm_processor.answer_question_simple(question, limit)

            # Process the answer
            if answer is not None:
                # Ensure answer is a string and strip whitespace
                processed_answer = str(answer).strip()
                logger.info(f"LLM generated answer for '{question}': '{processed_answer[:50]}...'")
                return processed_answer
            else:
                 logger.warning(f"LLM returned None for question '{question}'. Using fallback.")
                 return fallback_answer

        except LLMError as e: # Catch specific LLM errors if defined
             logger.error(f"LLM error generating answer for '{question}': {e}", exc_info=True)
             return fallback_answer
        except Exception as e:
            # Catch unexpected errors during LLM interaction
            logger.critical(f"Unexpected error during LLM answer generation for '{question}': {e}", exc_info=True)
            return fallback_answer